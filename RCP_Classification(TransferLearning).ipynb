{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer Learning을 통한 가위-바위-보 분류 분석 모델의 성능 개선_배포.ipynb","provenance":[{"file_id":"1d8zJF-i9AyMOTjgmFsQpQkC3eyZkD6zz","timestamp":1627436503085},{"file_id":"1RXXbf_Cxr7dIIPKdbOKxWIuE84M_drTg","timestamp":1624087211684}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bGEqpQmA_WZ6"},"source":["from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Bht6Z5Cbnm_"},"source":["## Transfer Learning 을 통한 가위-바위-보 분류 데이터 셋 분류 성능 개선"]},{"cell_type":"markdown","metadata":{"id":"LhbHXd2ZI1t3"},"source":["### Step 1. Input tensor 와 Target tensor 준비(훈련데이터)"]},{"cell_type":"markdown","metadata":{"id":"axECPsnlb5lA"},"source":["(1) 가위-바위-보 데이터셋 다운로드"]},{"cell_type":"code","metadata":{"id":"wpywvV4KMjIE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627436552428,"user_tz":-540,"elapsed":2737,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"e8535968-a75b-4ad7-f8b8-7d1fa450aee2"},"source":["url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'\n","\n","path_to_zip = keras.utils.get_file('rps.zip',\n","                                   origin=url,\n","                                   extract=True,\n","                                   cache_dir='/content')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n","200687616/200682221 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6CFDzcUpM2wJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627436554335,"user_tz":-540,"elapsed":697,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"7682b14f-91a5-4960-86ed-8af338aac129"},"source":["url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n","\n","path_to_zip = keras.utils.get_file('rps_test.zip',\n","                                   origin=url,\n","                                   extract=True,\n","                                   cache_dir='/content')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n","29523968/29516758 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n5iHfTAhb-SM"},"source":["(2) ImageDataGenerator를 이용해 이미지 파일을 load 하기 위한 경로 지정"]},{"cell_type":"code","metadata":{"id":"gmGW7BsTNbRz"},"source":["train_dir = '/content/datasets/rps'\n","test_dir = '/content/datasets/rps-test-set'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FJj4NG2ucAfU"},"source":["(3) ImageDataGenerator 객체 생성  \n","* 객체 생성 시 rescale 인자를 이용하여 텐서 내 원소의 범위를 [0 ~ 255] => [0 ~ 1] 로 ReScaling 진행"]},{"cell_type":"code","metadata":{"id":"-DT1tnXgMoo0"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"toobDJJUMslq"},"source":["# 모든 이미지를 1/255로 스케일을 조정합니다\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   validation_split=0.2)\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OsAYG-IhcgsL"},"source":["* .flow_from_directory() 메서드를 이용하여 학습데이터와 검증데이터를 위한 DirectoryIterator 객체 생성"]},{"cell_type":"code","metadata":{"id":"QWdw-5EKMywK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627436576100,"user_tz":-540,"elapsed":675,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"7d62b2dd-86a4-45f0-e37a-49c308c833b1"},"source":["train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(224, 224),\n","        batch_size=20,\n","        shuffle=True,\n","        class_mode='categorical',\n","        subset='training',\n","        seed=7)\n","\n","validation_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(224, 224),\n","        batch_size=20,\n","        shuffle=True,\n","        class_mode='categorical',\n","        subset='validation',\n","        seed=7)\n","\n","test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(224, 224),\n","        batch_size=20,\n","        class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 2016 images belonging to 3 classes.\n","Found 504 images belonging to 3 classes.\n","Found 372 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"stk917_Sci0V"},"source":["### Step 2. VGG16을 Backbone 으로 하는 모델 디자인 및 학습 정보 설정"]},{"cell_type":"markdown","metadata":{"id":"BP8hv-ZCcnQx"},"source":["(1) Pre-trained 된 VGG16 모델 객체 생성\n","  * imagenet 데이터를 이용해 학습된 모델 객체 생성\n","  * classification layer 제외"]},{"cell_type":"code","metadata":{"id":"SsBdZgjQS_9m"},"source":["from tensorflow.keras.applications import VGG16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHsguOaF7CMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627436943886,"user_tz":-540,"elapsed":6442,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"66c977df-7500-4b5e-d226-0cc0c89c41dd"},"source":["conv_base = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WiqnkRJZ2SHO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627436998503,"user_tz":-540,"elapsed":308,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"07bfe9d0-ac79-4046-ef0b-c09107cd9bd4"},"source":["conv_base.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"18TfCRgEc_mb"},"source":["(2) VGG16 Backbone 모델에 classification layer 추가"]},{"cell_type":"code","metadata":{"id":"tnwc5pXX3f8x"},"source":["model = keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xe8HApyF8YEk"},"source":["model.add(conv_base)\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dense(units=256,activation='relu'))\n","model.add(keras.layers.Dense(units=3,activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_hBr1cJ4Hzd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627437103787,"user_tz":-540,"elapsed":278,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"b961819b-dc54-476d-fdc0-1839160c7c56"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               6422784   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 771       \n","=================================================================\n","Total params: 21,138,243\n","Trainable params: 21,138,243\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o4g29WFrdQYm"},"source":["(3) VGG16 Backbone 모델의 가중치 동결(학습대상 가중치에서 제외)"]},{"cell_type":"markdown","metadata":{"id":"jDhAapMbd8jW"},"source":["* VGG16 Backbone 모델의 가중치 동결 및 동결 후 학습대상 파라미터 개수 출력"]},{"cell_type":"code","metadata":{"id":"KHUnRXobd4aW","executionInfo":{"status":"ok","timestamp":1627437183316,"user_tz":-540,"elapsed":268,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}}},"source":["conv_base.trainable = False"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3Cxfyz78vCW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627437189634,"user_tz":-540,"elapsed":250,"user":{"displayName":"이호진","photoUrl":"","userId":"15675558772800035788"}},"outputId":"5328069e-58d2-41a1-f0bc-a9d35d38f4e5"},"source":["model.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               6422784   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 771       \n","=================================================================\n","Total params: 21,138,243\n","Trainable params: 6,423,555\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p58Gw79MePBh"},"source":["(4) 학습을 위한 설정 정보 지정"]},{"cell_type":"code","metadata":{"id":"spdqys60-4x4"},"source":["model.compile(optimizer='rmsprop',)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3D-ob5jkfmZe"},"source":["### Step 3. 모델에 데이터 generator 연결 후 학습 \n","  * model.fit() 이용하여 데이터 연결 및 학습시키기\n","  * 학습 과정은 history 변수에 저장"]},{"cell_type":"code","metadata":{"id":"eIl1NAH2-8Js"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9PS8aRYN_YJa"},"source":["### Step 4. 테스트 데이터 셋을 통한 모델의 성능 평가"]},{"cell_type":"code","metadata":{"id":"MQarZ9C3f64d"},"source":[""],"execution_count":null,"outputs":[]}]}